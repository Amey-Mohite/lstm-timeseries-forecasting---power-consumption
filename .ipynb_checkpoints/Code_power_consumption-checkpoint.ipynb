{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8003e8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c80a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f0f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data\n",
    "df_people = pd.read_csv(\"full occ csv (1).csv\")\n",
    "df_weather = pd.read_csv(\"weather-1 (1).csv\")\n",
    "df_electricity = pd.read_excel(\"consumption.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee6be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people = df_people.dropna(how='all')\n",
    "df_people =  df_people.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619b3e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = df_weather.dropna(how='all')\n",
    "df_weather = df_weather.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c26c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people['Date'] = pd.to_datetime(df_people['Date'], format='%d/%m/%Y')\n",
    "df_weather['READING DATE'] = pd.to_datetime(df_weather['READING DATE'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bee8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people = df_people[df_people['Date'].isin(list(df_weather['READING DATE']))].reset_index().drop(['index'],1)\n",
    "df_electricity = df_electricity[df_electricity['READING DATE'].isin(list(df_weather['READING DATE']))].reset_index().drop(['index'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b78a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_electricity = df_electricity.drop([\"H\",\"OPTIMA Half Hourly DATA\",\"Unnamed: 2\",\"CHANNEL TYPE\",\"UNITS\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a008d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_drop_columns = [list(df_electricity.columns)[i] for i in range(len(list(df_electricity.columns))) if i%2!=0]\n",
    "df_electricity = df_electricity.drop(electricity_drop_columns,1)\n",
    "df_electricity['00:00'] = df_electricity[list(df_electricity.columns)[-1]]\n",
    "df_electricity = df_electricity.drop([list(df_electricity.columns)[-2]],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bdf7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "whether_drop_columns = [list(df_weather.columns)[i] for i in range(len(list(df_weather.columns))) if i%2!=0]\n",
    "df_weather = df_weather.drop(whether_drop_columns,1)\n",
    "df_weather['00:00'] = df_weather['23:59:00']\n",
    "df_weather = df_weather.drop(['23:59:00'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25917d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(df_people[\"13:00\"]):\n",
    "    if j == 'UID card access problems':\n",
    "        df_people[\"13:00\"][i] = np.nan\n",
    "\n",
    "for k in df_people.columns:\n",
    "    for i,j in enumerate(df_people[k]):\n",
    "        if j == 'Sentry Juno installation - Sentry offline, no data 9th -22nd July' or j == 'Sentry Juno live but no data yet' or j == \"Sentry Juno put into offline mode\" or j == \"#\" or j == \" \":\n",
    "            df_people[k][i] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b391b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people = df_people.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53947a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = df_weather.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271abbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_people.shape,df_weather.shape,df_electricity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec023c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(df,date1,name):\n",
    "    dict1 = {}\n",
    "    df_col = list(df.columns)[1:]\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df_col)):\n",
    "            dict1[str(df.at[i,date1].date()) +' '+ df_col[j]] = df.at[i,df_col[j]]\n",
    "    return pd.DataFrame(dict1.items(),columns = ['Date',name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f7abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_people = get_dataframe(df_people,'Date','people')\n",
    "final_df_weather = get_dataframe(df_weather,'READING DATE','weather')\n",
    "final_df_electricity = get_dataframe(df_electricity,'READING DATE','power_consumption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed88ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_people.shape,final_df_weather.shape,final_df_electricity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df_people.merge(final_df_weather,on='Date').merge(final_df_electricity,on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ba24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73639d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame()\n",
    "for cols in final_df.drop(['Date', 'power_consumption'], axis = 1).columns:\n",
    "    timeseries_data = final_df[cols]\n",
    "    scaler = MinMaxScaler()\n",
    "    print(f'Cols : {cols}')\n",
    "    scaler.fit(np.array(timeseries_data).reshape(-1, 1))\n",
    "    scaled_train = scaler.transform(np.array(timeseries_data).reshape(-1, 1))\n",
    "    n_input = 4\n",
    "    n_features = 1\n",
    "    generator = TimeseriesGenerator(scaled_train, scaled_train, length=n_input, batch_size = 64)\n",
    "    X, y = generator[0]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, activation='relu', input_shape = (X.shape[1], X.shape[2]),return_sequences= True))\n",
    "    model.add(LSTM(32, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = 'adam', loss = 'mse')\n",
    "    print(f'Training for columns : {cols}')\n",
    "    model.fit(generator, epochs = 3, verbose = 1)\n",
    "    test_predictions = []\n",
    "    first_eval_batch = scaled_train[-n_input:]\n",
    "    current_batch = first_eval_batch.reshape((1, n_input, n_features))\n",
    "    future = 720\n",
    "    for i in range(future):\n",
    "        current_pred = model.predict(current_batch)[0]\n",
    "        test_predictions.append(current_pred)\n",
    "        current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)\n",
    "\n",
    "    true_predictions = scaler.inverse_transform(test_predictions)\n",
    "    temp_df[cols] = true_predictions.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c7fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730bef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.round()\n",
    "temp_df = abs(temp_df)\n",
    "final_df_forecasted = temp_df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1099e094",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_forecasted['power_consumption'] = np.zeros(720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43830f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd12cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_consumption_lst = final_df['power_consumption']\n",
    "final_df.drop(['power_consumption'], axis = 1, inplace = True)\n",
    "\n",
    "final_df['power_consumption'] = power_consumption_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13458cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_forecasted = pd.concat([final_df, final_df_forecasted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2141083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_forecasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54260b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = final_df_forecasted.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb1d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_forecasted.drop(['Date'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final_df_forecasted.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ce0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86692671",
   "metadata": {},
   "source": [
    "### Forecasting power consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f80e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_std = StandardScaler()\n",
    "scaler_std = scaler_std.fit(final_df_forecasted)\n",
    "final_df_trainscaled = scaler_std.transform(final_df_forecasted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86a79fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X = []\n",
    "Train_y = []\n",
    "\n",
    "n_Future = 720\n",
    "n_Past = 1440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate between the past observations limit and the length of the df and subtract the future(days to predict into the future) and add 1 \n",
    "for i in range(n_Past, len(final_df_trainscaled) - n_Future + 1):\n",
    "    #append each value to Train_X\n",
    "    Train_X.append(final_df_trainscaled[i - n_Past:i, 0:final_df.shape[1]])\n",
    "    #append CycleTime to the Train_y list [-1] is the col index of Cycletime\n",
    "    Train_y.append(final_df_trainscaled[i + n_Future - 1:i + n_Future, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb8fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Train_y = np.array(Train_X), np.array(Train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0520681",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train X shape : {Train_X.shape}')\n",
    "print(f'Train y shape : {Train_y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d79496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the DL model\n",
    "model = Sequential()\n",
    "#using relu as the activation\n",
    "model.add(LSTM(64, activation='relu', input_shape = (Train_X.shape[1], Train_X.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Train_y.shape[1]))\n",
    "\n",
    "#using adam as the activation\n",
    "model.compile(optimizer = 'adam', loss = 'mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7671903",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(Train_X, Train_y, \n",
    "                    epochs = 1, batch_size = 32,\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c21cd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc96ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_past = 721\n",
    "N_future = 720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c35323",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_period_dates = []\n",
    "date = datetime.datetime(2021,11,13)\n",
    "for i in range(30): \n",
    "    date += datetime.timedelta(days=1)\n",
    "    for j in range(24):\n",
    "        forecast_period_dates.append(str(date).split(' ')[0]+' '+str(j)+':00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3d1bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict using the observations from the previous data\n",
    "prediction = model.predict(Train_X[-N_future:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccaacea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d927bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat the predictions for the fututre days(given as input)\n",
    "predictions = np.repeat(prediction, final_df_forecasted.shape[1], axis=-1)\n",
    "#inverse_transform\n",
    "y_pred_future = scaler_std.inverse_transform(predictions)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3a1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the predictions to the list\n",
    " \n",
    "df_fr_final = pd.DataFrame({'Date':np.array(forecast_period_dates), 'power_consumption':y_pred_future})\n",
    "df_fr_final['Date'] = pd.to_datetime(df_fr_final['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fr_final['Date'] = pd.to_datetime(df_fr_final['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1290fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize = (15,4))\n",
    "ax = sns.lineplot(df_fr_final['Date'], df_fr_final['power_consumption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d32e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fr_final['people'] = temp_df['people']\n",
    "df_fr_final['weather'] = temp_df['weather']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd1db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fr_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a7315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddabb5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd6f28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc01e0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde7767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28f5c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951ed181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca1e4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c2b9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4045750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17758cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df1 = final_df[['people']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a81cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = final_df1.values\n",
    "values = values.astype('float32')\n",
    "reframed = series_to_supervised(values, 30, 1)\n",
    "scaler = MinMaxScaler()#scaler.inverse_transform\n",
    "scaled = scaler.fit_transform(reframed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f224521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "values = scaled\n",
    "n_train_hours = 27360\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e438cede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=20, batch_size=32, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924194ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740b48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce62309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, :]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24af97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, :]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a0e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "mse = mean_squared_error(inv_y, inv_yhat)\n",
    "print('Test MSE: %.3f' % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d5b265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d3a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed593c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a5343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c637bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e972f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fd2a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3505964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65347659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e6dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9383ea3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c88b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d280b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66724f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b561a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
